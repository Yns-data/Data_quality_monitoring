services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data

  init:
    image: apache/airflow:2.10.3
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
    volumes:
      - ./scripts:/opt/airflow/scripts
    user: root
    command: >
      bash -c "apt-get update && apt-get install -y git ca-certificates &&
      su airflow -c 'git config --global http.sslverify false' &&
      su airflow -c 'pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org -r /opt/airflow/scripts/requirements.txt' &&
      su airflow -c 'airflow db migrate' &&
      su airflow -c 'airflow users create --username admin --firstname Air --lastname Flow --role Admin --email admin@admin.com --password admin'"

  webserver:
    image: apache/airflow:2.10.3
    depends_on:
      - init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__FERNET_KEY: 'YOUR_FERNET_KEY'
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      # Configuration pour accéder à l'API locale
      API_BASE_URL: 'http://host.docker.internal:8000'
      # Variables d'environnement pour les scripts de qualité des données
      user: ${user}
      password: ${password}
      host: ${host}
      port: ${port}
      dbname: ${dbname}
      tablename: ${tablename}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./scripts:/opt/airflow/scripts
    ports:
      - "8080:8080"
    # Configuration réseau pour accéder à l'host
    extra_hosts:
      - "host.docker.internal:host-gateway"
    user: root
    command: >
      bash -c "apt-get update && apt-get install -y git ca-certificates &&
      su airflow -c 'git config --global http.sslverify false' &&
      su airflow -c 'pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org -r /opt/airflow/scripts/requirements.txt' &&
      su airflow -c 'airflow webserver'"

  scheduler:
    image: apache/airflow:2.10.3
    depends_on:
      - init
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      # Configuration pour accéder à l'API locale
      API_BASE_URL: 'http://host.docker.internal:8000'
      # Variables d'environnement pour les scripts de qualité des données
      user: ${user}
      password: ${password}
      host: ${host}
      port: ${port}
      dbname: ${dbname}
      tablename: ${tablename}
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./scripts:/opt/airflow/scripts
    # Configuration réseau pour accéder à l'host
    extra_hosts:
      - "host.docker.internal:host-gateway"
    user: root
    command: >
      bash -c "apt-get update && apt-get install -y git ca-certificates &&
      su airflow -c 'git config --global http.sslverify false' &&
      su airflow -c 'pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org -r /opt/airflow/scripts/requirements.txt' &&
      su airflow -c 'airflow scheduler'"

volumes:
  postgres-db-volume:
